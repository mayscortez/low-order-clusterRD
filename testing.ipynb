{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import designs_setup as ds\n",
    "import numpy as np\n",
    "from setup_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = [[1,2,3], [2,2], [1], [1,1,1,1], [], [2,2],[0,0,0]]\n",
    "x = {len(i) for i in myList}\n",
    "y = [len(i) for i in myList]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 15 25 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayleencortez/networkcausal2022/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "####### Construct Network ########\n",
    "\n",
    "N = 15**2        # population size\n",
    "n = 15\n",
    "NC = 5**2          # number of clusters\n",
    "nc = 5\n",
    "print(N,n,NC,nc)\n",
    "diag = 1        # maximum norm of direct effect\n",
    "r = 1.25        # ratio between indirect and direct effects\n",
    "p = 0.05        # treatment probability\n",
    "\n",
    "# Create lattice network\n",
    "A = lattice2Dsq(n,n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  1  1  1  2  2  2  3  3  3  4  4  4]\n",
      " [ 0  0  0  1  1  1  2  2  2  3  3  3  4  4  4]\n",
      " [ 0  0  0  1  1  1  2  2  2  3  3  3  4  4  4]\n",
      " [ 5  5  5  6  6  6  7  7  7  8  8  8  9  9  9]\n",
      " [ 5  5  5  6  6  6  7  7  7  8  8  8  9  9  9]\n",
      " [ 5  5  5  6  6  6  7  7  7  8  8  8  9  9  9]\n",
      " [10 10 10 11 11 11 12 12 12 13 13 13 14 14 14]\n",
      " [10 10 10 11 11 11 12 12 12 13 13 13 14 14 14]\n",
      " [10 10 10 11 11 11 12 12 12 13 13 13 14 14 14]\n",
      " [15 15 15 16 16 16 17 17 17 18 18 18 19 19 19]\n",
      " [15 15 15 16 16 16 17 17 17 18 18 18 19 19 19]\n",
      " [15 15 15 16 16 16 17 17 17 18 18 18 19 19 19]\n",
      " [20 20 20 21 21 21 22 22 22 23 23 23 24 24 24]\n",
      " [20 20 20 21 21 21 22 22 22 23 23 23 24 24 24]\n",
      " [20 20 20 21 21 21 22 22 22 23 23 23 24 24 24]]\n"
     ]
    }
   ],
   "source": [
    "clusters, clusters_flat = bf_clusters(NC,N)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14)\t1\n",
      "  (0, 43)\t1\n",
      "  (0, 44)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 74)\t1\n"
     ]
    }
   ],
   "source": [
    "i = 44\n",
    "print(A[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "k = int(np.ceil(n/nc))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (0, 5)]\n"
     ]
    }
   ],
   "source": [
    "lst = cluster_neighborhood(A,i,k)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4)\n",
      "2.0\n",
      "(0, 5)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 1 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mayleencortez/low-order-clusterRD/testing.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.236.181.15/home/mayleencortez/low-order-clusterRD/testing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lst:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B132.236.181.15/home/mayleencortez/low-order-clusterRD/testing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(l)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B132.236.181.15/home/mayleencortez/low-order-clusterRD/testing.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m((Cz[l]\u001b[39m/\u001b[39mp) \u001b[39m-\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mCz[l])\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mp))\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 1 with size 5"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "Cz, flatCz, z = bernoulli_cluster(n,p,clusters)\n",
    "for l in lst:\n",
    "    print(l)\n",
    "    print((Cz[l]/p) - (1-Cz[l])/(1-p))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterPI(A,Y,Cz,p):\n",
    "    '''\n",
    "    Returns an estimate of the TTE using the (beta=1) cluster pseudoinverse estimator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy sparse array\n",
    "        represents N x N adjacency matrix for a population of size N = n^2\n",
    "    Y : numpy array\n",
    "        N x 1 array of observed outcomes, one for each unit in the population\n",
    "    Cz : numpy array\n",
    "        nc by nc array of cluster treatement assignments (nc^2 is the number of clusters)\n",
    "        (s,t)-th element is treatment assignment of cluster (s,t) in [nc] x [nc]\n",
    "    p : float\n",
    "        treatment probability of any cluster\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TTE_hat/N : float\n",
    "        estimate of the total treatment effect\n",
    "    '''\n",
    "    N = np.shape(A)[0]     # population size\n",
    "    nc = np.shape(Cz)[0]   # square root of the number of clusters\n",
    "    n = int(np.sqrt(N))    # square root of population size\n",
    "    k = int(np.ceil(n/nc)) # \"typical\" cluster side length\n",
    "    \n",
    "    TTE_hat = 0\n",
    "    for i in range(N):\n",
    "        #print(i)\n",
    "        sum = 0\n",
    "        for c in cluster_neighborhood(A,i,k):\n",
    "            sum = sum + (Cz[c]/p) - (1-Cz[c])/(1-p)\n",
    "        TTE_hat = TTE_hat + Y[i]*sum\n",
    "    return TTE_hat/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ht_weights_bernoulli(N,p,neighborhoods):\n",
    "    '''\n",
    "    Returns the inverse probability weights for Horvitz-Thompson estimator under Bernoulli(p) cluster design\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        number of units in the population (n^2)\n",
    "    p : float\n",
    "        cluster treatment probability\n",
    "    neighborhoods: list\n",
    "        each entry i contains a list of clusters adjacent to i, i.e. the cluster neighborhood of i\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    w1 : 1D numpy array\n",
    "        w1[i] = 1/Prob(i's neighborhood fully assigned to treatment)\n",
    "    w0 : 1D numpy array\n",
    "        w0[i] = 1/Prob(i's neighborhood fully assigned to control); inverse prob weight\n",
    "    '''\n",
    "    w1 = np.zeros(N)    # w1[i] = 1/Prob(i's neighborhood fully assigned to treatment)\n",
    "    w0 = np.zeros(N)    # w0[i] = 1/Prob(i's neighborhood fully assigned to control)\n",
    "    K = [len(i) for i in neighborhoods] # K[i] = size of i's cluster neighborhood\n",
    "    w1 = 1/p**K\n",
    "    w0 = 1/(1-p)**K\n",
    "\n",
    "    return w1,w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ht(p,z,w1,w0,A,Y):\n",
    "    '''\n",
    "    Returns the Horvitz-Thompson estimate of the TTE\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : float\n",
    "        treatment probability of clusters in Bernoulli(p) cluster design\n",
    "    z : 1D numpy array\n",
    "        z[i] = treatment assignment of unit i in a population of size n^2\n",
    "    w1: 1D numpy array\n",
    "        w1[i] = 1/Prob(i's neighborhood fully assigned to treatment); inverse prob weight\n",
    "    w0: 1D numpy array\n",
    "        w0[i] = 1/Prob(i's neighborhood fully assigned to control); inverse prob weight\n",
    "    A : scipy sparse array\n",
    "        represents N x N adjacency matrix for a population of size N = n^2\n",
    "    Y : 1D numpy array\n",
    "        Y[i] = observed outcome of unit i in a population of size n^2\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    est : float\n",
    "        Horvitz-Thompson estimate of the TTE\n",
    "    '''\n",
    "    N = np.shape(A)[0]  # population size\n",
    "    est=0\n",
    "\n",
    "    Ind1 = np.zeros(N)  # Ind1[i] = Indicator(i's neighborhood fully assigned to treatment)\n",
    "    Ind0 = np.zeros(N)  # Ind0[i] = Indicator(i's neighborhood fully assigned to control)\n",
    "    Ind1 = (A.dot(z) == A.sum(axis=1)) + 0\n",
    "    Ind0 = (A.dot(z) == np.zeroes(N)) + 0\n",
    "\n",
    "    est = (1/N) * np.sum(Y.dot(Ind1/w1 - Ind0/w0))\n",
    "    return est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment to test the unbiasedness of the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Construct Network ########\n",
    "\n",
    "N = 900        # population size\n",
    "n = int(np.sqrt(N))\n",
    "NC = 100          # number of clusters\n",
    "nc = int(np.sqrt(NC))\n",
    "#print(N,n,NC,nc)\n",
    "diag = 1        # maximum norm of direct effect\n",
    "r = 1.25        # ratio between indirect and direct effects\n",
    "p = 0.05        # treatment probability\n",
    "\n",
    "# Create lattice network\n",
    "A = lattice2Dsq(n,n)\n",
    "\n",
    "# Generate edge weights\n",
    "rand_wts = np.random.rand(N,3)\n",
    "alpha = rand_wts[:,0].flatten()\n",
    "C = simpleWeights(A, diag, r*diag, rand_wts[:,1].flatten(), rand_wts[:,2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-Truth TTE: 1.1391062385491877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Potential Outcomes Model\n",
    "fy = lambda z: linear_pom(C,alpha,z)\n",
    "\n",
    "# Calculate and print ground truth TTE\n",
    "TTE = 1/N * np.sum((fy(np.ones(N)) - fy(np.zeros(N))))\n",
    "print(\"Ground-Truth TTE: {}\\n\".format(TTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clusters = bf_clusters(NC,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Estimate ########\n",
    "\n",
    "p = 0.5    # treatment probability\n",
    "T = 500   # number of trials\n",
    "\n",
    "#TTE_PI, TTE_ht, TTE_hajek = np.zeros(T), np.zeros(T), np.zeros(T)\n",
    "TTE_PI= np.zeros(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(T):\n",
    "  Cz, flatCz, z = bernoulli_cluster(n,p,clusters)\n",
    "  Y = fy(z)\n",
    "  #print(i)\n",
    "  TTE_PI[i] = clusterPI(A,Y,Cz,p)\n",
    "  #TTE_ht[i] = ht(n,p,Y,A,z)\n",
    "  #TTE_hajek[i] = hajek(n,p,y,A,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours: 0.013716418068646223\n",
      "Our bias: 1.1253898204805415\n",
      "Our MSE: 1.4557261130085148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ours: {}\".format(np.sum(TTE_PI)/T))\n",
    "print(\"Our bias: {}\".format(TTE-(np.sum(TTE_PI)/T)))\n",
    "print(\"Our MSE: {}\\n\".format(np.sum((TTE_PI-TTE)**2)/T))\n",
    "\n",
    "# print(\"H-T: {}\".format(np.sum(TTE_ht)/T))\n",
    "# print(\"H-T MSE: {}\\n\".format(np.sum((TTE_ht-TTE)**2)/T))\n",
    "\n",
    "# print(\"Hajek: {}\".format(np.sum(TTE_hajek)/T))\n",
    "# print(\"Hajek MSE: {}\".format(np.sum((TTE_hajek-TTE)**2)/T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When $k$ divides $n$\n",
    "First, I'm testing whether my code works when $k | n$. I'm making the choice that when $k | n$ we don't sample a random origin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster : I   J\n",
      "(0, 0) : [0 1 2] [0 1 2]\n",
      "(0, 1) : [0 1 2] [3 4 5]\n",
      "(0, 2) : [0 1 2] [6 7 8]\n",
      "(0, 3) : [0 1 2] [ 9 10 11]\n",
      "\n",
      "(1, 0) : [3 4 5] [0 1 2]\n",
      "(1, 1) : [3 4 5] [3 4 5]\n",
      "(1, 2) : [3 4 5] [6 7 8]\n",
      "(1, 3) : [3 4 5] [ 9 10 11]\n",
      "\n",
      "(2, 0) : [6 7 8] [0 1 2]\n",
      "(2, 1) : [6 7 8] [3 4 5]\n",
      "(2, 2) : [6 7 8] [6 7 8]\n",
      "(2, 3) : [6 7 8] [ 9 10 11]\n",
      "\n",
      "(3, 0) : [ 9 10 11] [0 1 2]\n",
      "(3, 1) : [ 9 10 11] [3 4 5]\n",
      "(3, 2) : [ 9 10 11] [6 7 8]\n",
      "(3, 3) : [ 9 10 11] [ 9 10 11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 12\n",
    "k = 3\n",
    "\n",
    "print('Cluster',':','I ',' J')\n",
    "for i in range(n//k):\n",
    "    for j in range(n//k):\n",
    "        I,J = ds.sqlat_toUnit(i,j,k,n)\n",
    "        print((i,j),':', I,J)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [0 0]\n"
     ]
    }
   ],
   "source": [
    "I = np.array([1,2])\n",
    "J = np.array([1,2])\n",
    "s,t = ds.sqlat_toCluster(I,J,k,divides=True)\n",
    "print(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit : Cluster\n",
      "(5, 0) : (1, 0)\n",
      "(5, 1) : (1, 0)\n",
      "(5, 2) : (1, 0)\n",
      "(5, 3) : (1, 1)\n",
      "(5, 4) : (1, 1)\n",
      "(5, 5) : (1, 1)\n",
      "(5, 6) : (1, 2)\n",
      "(5, 7) : (1, 2)\n",
      "(5, 8) : (1, 2)\n",
      "(5, 9) : (1, 3)\n",
      "(5, 10) : (1, 3)\n",
      "(5, 11) : (1, 3)\n",
      "\n",
      "(10, 0) : (3, 0)\n",
      "(10, 1) : (3, 0)\n",
      "(10, 2) : (3, 0)\n",
      "(10, 3) : (3, 1)\n",
      "(10, 4) : (3, 1)\n",
      "(10, 5) : (3, 1)\n",
      "(10, 6) : (3, 2)\n",
      "(10, 7) : (3, 2)\n",
      "(10, 8) : (3, 2)\n",
      "(10, 9) : (3, 3)\n",
      "(10, 10) : (3, 3)\n",
      "(10, 11) : (3, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Unit', ':', 'Cluster')\n",
    "for i in [5,10]:\n",
    "    for j in range(n):\n",
    "        s,t = ds.sqlat_toCluster(i,j,k,divides=True)\n",
    "        print((i,j),':',(s,t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster : I   J\n",
      "(0, 0) : [0 1 2 3] [0 1 2 3]\n",
      "(0, 1) : [0 1 2 3] [4 5 6 7]\n",
      "(0, 2) : [0 1 2 3] [ 8  9 10 11]\n",
      "\n",
      "(1, 0) : [4 5 6 7] [0 1 2 3]\n",
      "(1, 1) : [4 5 6 7] [4 5 6 7]\n",
      "(1, 2) : [4 5 6 7] [ 8  9 10 11]\n",
      "\n",
      "(2, 0) : [ 8  9 10 11] [0 1 2 3]\n",
      "(2, 1) : [ 8  9 10 11] [4 5 6 7]\n",
      "(2, 2) : [ 8  9 10 11] [ 8  9 10 11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "\n",
    "print('Cluster',':','I ',' J')\n",
    "for i in range(n//k):\n",
    "    for j in range(n//k):\n",
    "        I,J = ds.sqlat_toUnit(i,j,k,n)\n",
    "        print((i,j),':', I,J)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit : Cluster\n",
      "(3, 0) : (0, 0)\n",
      "(3, 1) : (0, 0)\n",
      "(3, 2) : (0, 0)\n",
      "(3, 3) : (0, 0)\n",
      "(3, 4) : (0, 1)\n",
      "(3, 5) : (0, 1)\n",
      "(3, 6) : (0, 1)\n",
      "(3, 7) : (0, 1)\n",
      "(3, 8) : (0, 2)\n",
      "(3, 9) : (0, 2)\n",
      "(3, 10) : (0, 2)\n",
      "(3, 11) : (0, 2)\n",
      "\n",
      "(9, 0) : (2, 0)\n",
      "(9, 1) : (2, 0)\n",
      "(9, 2) : (2, 0)\n",
      "(9, 3) : (2, 0)\n",
      "(9, 4) : (2, 1)\n",
      "(9, 5) : (2, 1)\n",
      "(9, 6) : (2, 1)\n",
      "(9, 7) : (2, 1)\n",
      "(9, 8) : (2, 2)\n",
      "(9, 9) : (2, 2)\n",
      "(9, 10) : (2, 2)\n",
      "(9, 11) : (2, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Unit', ':', 'Cluster')\n",
    "for i in [3,9]:\n",
    "    for j in range(n):\n",
    "        s,t = ds.sqlat_toCluster(i,j,k,divides=True)\n",
    "        print((i,j),':',(s,t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When $k$ doesn't divide $n$\n",
    "Now I want to test what happens when $k$ does not divide $n$ and hence we sample an origin point $(q_1,q_2).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "n = 7\n",
    "k = 2\n",
    "print(n%k == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "# sample origin\n",
    "rng = default_rng()\n",
    "q1 = rng.integers(low=0, high=k)\n",
    "q2 = rng.integers(low=0, high=k)\n",
    "print(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster : I     J\n",
      "(0, 0) : [0 1] [0]\n",
      "(0, 1) : [0 1] [1 2]\n",
      "(0, 2) : [0 1] [3 4]\n",
      "(0, 3) : [0 1] [5 6]\n",
      "\n",
      "(1, 0) : [2 3] [0]\n",
      "(1, 1) : [2 3] [1 2]\n",
      "(1, 2) : [2 3] [3 4]\n",
      "(1, 3) : [2 3] [5 6]\n",
      "\n",
      "(2, 0) : [4 5] [0]\n",
      "(2, 1) : [4 5] [1 2]\n",
      "(2, 2) : [4 5] [3 4]\n",
      "(2, 3) : [4 5] [5 6]\n",
      "\n",
      "(3, 0) : [6] [0]\n",
      "(3, 1) : [6] [1 2]\n",
      "(3, 2) : [6] [3 4]\n",
      "(3, 3) : [6] [5 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num = np.ceil(n/k)\n",
    "print('Cluster',':','I  ','  J')\n",
    "for i in range(num.astype(int)):\n",
    "    for j in range(num.astype(int)):\n",
    "        I,J = ds.sqlat_toUnit(i,j,k,n,q1,q2)\n",
    "        print((i,j),':', I,J)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "q1 = rng.integers(low=0, high=k)\n",
    "q2 = rng.integers(low=0, high=k)\n",
    "print(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster : I     J\n",
      "(0, 0) : [0] [0]\n",
      "(0, 1) : [0] [1 2]\n",
      "(0, 2) : [0] [3 4]\n",
      "(0, 3) : [0] [5 6]\n",
      "\n",
      "(1, 0) : [1 2] [0]\n",
      "(1, 1) : [1 2] [1 2]\n",
      "(1, 2) : [1 2] [3 4]\n",
      "(1, 3) : [1 2] [5 6]\n",
      "\n",
      "(2, 0) : [3 4] [0]\n",
      "(2, 1) : [3 4] [1 2]\n",
      "(2, 2) : [3 4] [3 4]\n",
      "(2, 3) : [3 4] [5 6]\n",
      "\n",
      "(3, 0) : [5 6] [0]\n",
      "(3, 1) : [5 6] [1 2]\n",
      "(3, 2) : [5 6] [3 4]\n",
      "(3, 3) : [5 6] [5 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num = np.ceil(n/k)\n",
    "print('Cluster',':','I  ','  J')\n",
    "for i in range(num.astype(int)):\n",
    "    for j in range(num.astype(int)):\n",
    "        I,J = ds.sqlat_toUnit(i,j,k,n,q1,q2)\n",
    "        print((i,j),':', I,J)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('networkcausal2022': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eebfb57edd8d04f6c7400c7f1b4e1ce915b8b01987519f009093ec2688412c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
